{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f61327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "sales_df = pd.read_csv(\"train.csv\", delimiter=',')\n",
    "\n",
    "predictions = []\n",
    "for dataframe in arr3:\n",
    "    predictions.append(np.squeeze(np.squeeze(model.predict(np.expand_dims(dataframe[-N_PAST:].values, axis=0)), axis=0), axis=-1))\n",
    "\n",
    "arr = []\n",
    "\n",
    "for i in range(len(sales_df.item.unique())):\n",
    "    mask = sales_df.item == sales_df.item.unique()[i]\n",
    "    arr.append(sales_df[mask])\n",
    "\n",
    "arr2 = []\n",
    "\n",
    "for dataframe in arr:\n",
    "    for i in range(len(dataframe.store.unique())):\n",
    "        mask = dataframe.store == dataframe.store.unique()[i]\n",
    "        arr2.append(dataframe[mask])\n",
    "\n",
    "for dataframe in arr2:\n",
    "    dataframe.date = pd.to_datetime(dataframe['date'])\n",
    "\n",
    "for dataframe in arr2:\n",
    "    dataframe.set_index('date', inplace=True)\n",
    "'''\n",
    "def windowed_dataset(series, batch_size, n_past=365, n_future=30, shift=1, shuffle_buffer=1000):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size = n_past+n_future, shift = shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(n_past+n_future))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:n_past], w[n_past:,2]))\n",
    "    \n",
    "    return ds.batch(batch_size).prefetch(1)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "N_PAST = 360\n",
    "N_FUTURE = 90\n",
    "SHIFT = 1\n",
    "SHUFFLE_BUFFER = 1000\n",
    "N_FEATURE = 3\n",
    "\n",
    "trained_list = []\n",
    "\n",
    "for dataframe in arr2:\n",
    "    trained_list.append(windowed_dataset(series=dataframe.values, batch_size=BATCH_SIZE,\n",
    "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
    "                                 shift=SHIFT, shuffle_buffer=SHUFFLE_BUFFER))\n",
    "\n",
    "dataset = trained_list[0]\n",
    "for i in range(1, len(trained_list)):\n",
    "    dataset = dataset.concatenate(trained_list[i])\n",
    "\n",
    "num_elements = 0\n",
    "for element in dataset:\n",
    "    num_elements += 1\n",
    "        \n",
    "print(num_elements)\n",
    "\n",
    "train_size = int(0.9 * num_elements)\n",
    "val_size = int(0.1 * num_elements)\n",
    "\n",
    "dataset.shuffle(1000)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "\n",
    "validation_dataset = dataset.skip(train_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=[N_PAST,N_FEATURE]),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Reshape((N_FUTURE,int(math.ceil(N_PAST*32/N_FUTURE)))),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        \n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss = tf.keras.losses.Huber()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics='mae')\n",
    "\n",
    "history = model.fit(train_dataset, epochs=5, verbose=1, validation_data=validation_dataset)\n",
    "\n",
    "model.save('sales_forcasting_single_model')'''\n",
    "\n",
    "model = tf.keras.models.load_model('sales_forcasting_single_model')\n",
    "\n",
    "np_prediction = np.empty([0,])\n",
    "for dataframe in arr2:\n",
    "    np_prediction = np.append(np_prediction, np.rint(np.squeeze(np.squeeze(model.predict(np.expand_dims(dataframe[-N_PAST:].values, axis=0)), axis=0), axis=-1)))\n",
    "\n",
    "submission_pd = pd.read_csv(\"D:\\\\Technical Education\\\\CV Repository\\\\CV-Repository\\\\Sales Forecasting\\\\data\\\\test.csv\", delimiter=',')\n",
    "submission_pd['prediction'] = np_prediction\n",
    "\n",
    "submission_pd.to_csv(\"D:\\\\Technical Education\\\\CV Repository\\\\CV-Repository\\\\Sales Forecasting\\\\result\\\\submission_single_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0934cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
